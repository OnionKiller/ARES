Query	Document	Answer
what's delta sharing?	Delta Sharing ===============    **Applies to:**  ![check marked yes](../../_images/check.png)  Databricks SQL  ![check marked yes](../../_images/check.png)  Databricks Runtime 10.3 and above  ![check marked yes](../../_images/check.png)  Unity Catalog only       Delta Sharing is an open protocol for secure data sharing with other organizations regardless of which computing platforms they use. It can share collections of tables in a Unity Catalog metastore in real time without copying them, so that data recipients can immediately begin working with the latest version of the shared data.       There are three components to Delta Sharing:     * **[Providers](#providers)**      A provider is an entity which has made data available for sharing. * **[Shares](#shares)**      A share defines a logical grouping for the tables you intend to share. * **[Recipients](#recipients)**      A recipient identifies an organization with which you want to share any number of shares.     For a detailed guide on how to use Delta Sharing see  [Share data securely using Delta Sharing](../../data-sharing/index.html)  .        	Delta Sharing is an open protocol for secure data sharing with other organizations regardless of which computing platforms they use. It can share collections of tables in a Unity Catalog metastore in real time without copying them, so that data recipients can immediately begin working with the latest version of the shared data.
how to remove partitions of a delta table?	Best practices for dropping a managed Delta Lake table Learn the best practices for dropping a managed Delta Lake table.   Written by Adam Pavlacka  Last published at: May 10th, 2022 Regardless of how you drop a managed table, it can take a significant amount of time, depending on the data size. Delta Lake managed tables in particular contain a lot of metadata in the form of transaction logs, and they can contain duplicate data files. If a Delta table has been in use for a long time, it can accumulate a very large amount of data.  In the Databricks environment, there are two ways to drop tables (AWS | Azure | GCP):  Run DROP TABLE in a notebook cell. Click Delete in the UI. Even though you can delete tables in the background without affecting workloads, it is always good to make sure that you run DELETE FROM (AWS | Azure | GCP) and VACUUM (AWS | Azure | GCP) before you start a drop command on any table. This ensures that the metadata and file sizes are cleaned up before you initiate the actual data deletion.  For example, if you are trying to delete the Delta table events, run the following commands before you start the DROP TABLE command:  Run DELETE FROM: DELETE FROM events Run VACUUM with an interval of zero: VACUUM events RETAIN 0 HOURS These two steps reduce the amount of metadata and number of uncommitted files that would otherwise increase the data deletion time. 	To remove partitions of a Delta table, you can use the DELETE FROM and VACUUM commands before initiating the DROP TABLE command. For example, if you want to delete the Delta table "events", you can run the following commands: DELETE FROM events and VACUUM events RETAIN 0 HOURS. These steps will reduce the amount of metadata and uncommitted files, which can help to decrease the time it takes to delete the data.
explain medalian architecture on databricks	What is the medallion lakehouse architecture? ===============================================     The medallion architecture describes a series of data layers that denote the quality of data stored in the lakehouse. Databricks recommends taking a multi-layered approach to building a single source of truth for enterprise data products. This architecture guarantees atomicity, consistency, isolation, and durability as data passes through multiple layers of validations and transformations before being stored in a layout optimized for efficient analytics. The terms  [bronze](#bronze)  (raw),  [silver](#silver)  (validated), and  [gold](#gold)  (enriched) describe the quality of the data in each of these layers.       It is important to note that this medallion architecture does not replace other dimensional modeling techniques. Schemas and tables within each layer can take on a variety of forms and degrees of normalization depending on the frequency and nature of data updates and the downstream use cases for the data.       Organizations can leverage the Databricks Lakehouse to create and maintain validated datasets accessible throughout the company. Adopting an organizational mindset focused on curating data-as-products is a key step in successfully building a data lakehouse.	The medallion architecture is a multi-layered approach to building a single source of truth for enterprise data products. It guarantees atomicity, consistency, isolation, and durability as data passes through multiple layers of validations and transformations before being stored in a layout optimized for efficient analytics. The terms bronze (raw), silver (validated), and gold (enriched) describe the quality of the data in each of these layers. The bronze layer contains unvalidated data, the silver layer represents a validated, enriched version of the data, and the gold layer contains highly refined and aggregated data that powers analytics, machine learning, and production applications.